<html>
<head>
<meta charset="UTF-8">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/a17t@latest/dist/a17t.css">
<link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">
</head>

<body class="max-w-full overflow-x-hidden bg-neutral-50">

<div class="max-w-screen-lg px-6 py-4 mx-auto lg:mx-auto md:py-8">

<section class="content">

<h1>A plan for Benchmarking Cython+</h1>

<h2>Goals</h2>

<p>As part of the Cython+ project, this subproject will have to help evaluate the benefits of Cython+ against the <em>statu quo</em> (CPython and Stefan Behnel's Cython) and alternative approaches (various Python JIT accelerators, including Numba, and).</p>

<p>More specifically, we will have to evaluate Cython+ along two axes:</p>

<ol>
<li>How more performant (in terms of elapsed time, CPU and memory consumption) Cython+ is.</li>
<li>How improved (or degraded) the developer experience (DX) is relative to the baselines, in terms of:
<ol>
<li>Compilation time</li>
<li>Startup time</li>
<li>How different it is from standard Python (in terms of both added and removed features)</li>
<li>Support from and from the Python tooling ecosystem (formatters, linters, IDEs...) and the Python librairies</li>
<li>Language support for things that can't be done (easily) in standard Python</li>
</ol></li>
</ol>

<p>The "performance" part is mostly numerical. The "DX" part has some numerical, but most of it is qualitative.</p>

<h2>Current state</h2>

<p>I have created a project for running and reporting benchmarks of Cython+ against both regular implementations of Python and Cython (including some exotic variants), and other languages: </p>

<ul>
<li>GitHub project: <a href="https://github.com/abilian/python-benchmarks">https://github.com/abilian/python-benchmarks</a></li>
<li>Results: <a href="https://lab.abilian.com/">https://lab.abilian.com/</a></li>
</ul>

<h2>General observations</h2>

<h3>3 Levels of benchmarks</h3>

<p>We will have to consider three main categories of benchmarks, which each provide different insights:</p>

<ol>
<li><p>Micro and mini benchmarks (from 10 to a few 100s of LOC). This is the easiest category to start with, and also the only one that allow rigourous comparison between languages or language variants.</p></li>
<li><p>Benchmarking based on existing librairies (ex: SQLAlchemy, Jinja2, etc.) or applications (ex: PyDis, see below). This category is probably the most useful for users, but it will be quite hard to do in our context since a big part of the benefits of using Cython comes at the price of changes in the syntax (if not the semantics) of the language.</p></li>
<li><p>Benchmarking of applications specifically written for the project (see below).</p></li>
</ol>

<h3>Benchmarks for various use cases</h3>

<p>Benchmarks are only relevant for a class of applications.</p>

<p>We will classify our micro-benchmarks in several categories:</p>

<ol>
<li>Non-numerical algorithms</li>
<li>Numerical algorithms
<ol>
<li>Scalar</li>
<li>Vector</li>
</ol></li>
<li>Networked apps</li>
</ol>

<p>And provide synthetic marks for various usage profiles based on the weighted results of these benchmarks.</p>

<h3>Benchmarks against relevant contenders</h3>

<p>No need to benchmark against all the existing language. We will choose a subset:</p>

<ul>
<li>Languages most similar to Python ("Scripting languages"): JS, Ruby, Lua.</li>
<li>Most performant languages as of today: C and C++</li>
<li>Additional newcomers: Go, Rust, maybe a couple other...</li>
<li>Maybe Pony because it's also an actor-based language ?</li>
</ul>

<h2>Current plan</h2>

<ul>
<li>[x] Run a decent set of micro and mini benchmarks with a decent set of languages and language variants. (WIP)</li>
<li>[ ] Identify a subset of these benchmarks that correspond to the main use cases outlined above</li>
<li>[ ] Add currently missing implementations of the programs (from the Debian Computer Language Benchmarks Game)</li>
<li>[ ] Check that the results are indeed corrects for all the implementations</li>
<li>[ ] Make a decent website to present the results</li>
<li>[ ] Compute and present synthetic marks for each of the main use cases</li>
<li>[ ] Run benchmarks remotely on various machines
<ul>
<li>[ ] Small (Raspberry Pi, Single CPU x86)</li>
<li>[ ] Medium (Core i5 or similar)</li>
<li>[ ] Large and very large (Rapid.Space ?)</li>
<li>[ ] "Exotic" (RISC-V board ?)</li>
</ul></li>
<li>[ ] Add a few "exotic" implementations of Python to the mix
<ul>
<li>[ ] Pyjion</li>
<li>[ ] Pyston</li>
<li>[ ] Micropython and variants</li>
<li>[ ] tpythonpp</li>
</ul></li>
<li>[ ] Implement higher level benchmarks i.e. PyDis, the Web Server, etc.</li>
</ul>

<h2>Projets to Cythonize+ for benchmarking</h2>

<ul>
<li>[ ] Web server</li>
<li>[ ] Pydis (see below)</li>
</ul>

<h3>Pydis</h3>

<ul>
<li>[ ] Trouver un moyen de paralléliser</li>
<li>[ ] Re-implementer Pydis en:
<ul>
<li>[ ] Cython</li>
<li>[ ] Cython+ / Acthon</li>
<li>[ ] One or more of Go, Rust, Swift, V, Pony, Zig, Nim</li>
</ul></li>
</ul>

<p>Additional databases that could be cythonized+ and/or used as benchmarks without changes:</p>

<ul>
<li>[ ] <a href="https://github.com/msiemens/tinydb">GitHub - msiemens/tinydb: TinyDB is a lightweight document oriented database optimized for your happiness :)</a> + benchmarks</li>
<li>[ ] Buzhug (= tinydb)</li>
<li>[ ] BlackSheep (already Cythonized)</li>
</ul>

<h3>Web server / app server</h3>

<p>See dedicated page.</p>

<h2>Notes</h2>

<blockquote>
  <p><em>Google originally optimized the V8 JIT using the Richards benchmark, because its a good test of polymorphism and how classes are often used.</em>
   -- Source: <a href="https://medium.com/analytics-vidhya/77x-faster-than-rustpython-f8331c46aea1">https://medium.com/analytics-vidhya/77x-faster-than-rustpython-f8331c46aea1</a></p>
</blockquote>

<ul>
<li>The <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/">Debian Computer Language Benchmarks Game</a></li>
<li><a href="https://github.com/Dundee/pybenchmarks">https://github.com/Dundee/pybenchmarks</a> / >https://pybenchmarks.org/></li>
<li><a href="https://github.com/smarr/are-we-fast-yet">https://github.com/smarr/are-we-fast-yet</a> - Are We Fast Yet? Comparing Language Implementations with Objects, Closures, and Arrays (Pas de Python)</li>
<li><a href="https://github.com/ltratt/vms_experiment">https://github.com/ltratt/vms_experiment</a> - Benchmark suite for dynamically typed languages and VMs</li>
<li><a href="https://pyperformance.readthedocs.io/benchmarks.html">https://pyperformance.readthedocs.io/benchmarks.html</a></li>
<li><a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/measurements/python3.html">https://benchmarksgame-team.pages.debian.net/benchmarksgame/measurements/python3.html</a></li>
<li><a href="https://arxiv.org/pdf/1903.10267.pdf">On Evaluating the Renaissance Benchmarking Suite: Variety, Performance, and Complexity</a> (pour la JVM). See also: https://github.com/renaissance-benchmarks/renaissance</li>
</ul>


<h2>Older benchmarks (by Nexedi)</h2>

<blockquote>
<p>La page :
- <a href="https://www.nexedi.com/NXD-Blog.Multicore.Python.HTTP.Server">https://www.nexedi.com/NXD-Blog.Multicore.Python.HTTP.Server</a></p>

<p>contient un tableau utile pour comparer des librairies de coroutines.</p>

<p>Et la page :
- <a href="https://www.nexedi.com/NXD-Blog.Cython.Multithreaded.Coroutines">https://www.nexedi.com/NXD-Blog.Cython.Multithreaded.Coroutines</a></p>

<p>donne une idée des performances relatives de coroutines.</p>

<p>Si cela t'intéresse, j'aimerais bien avoir une évaluation de haproxy vs. lwan selon les mêmes principes.</p>

</blockquote>

</section>
</div>

</body>
</html>
